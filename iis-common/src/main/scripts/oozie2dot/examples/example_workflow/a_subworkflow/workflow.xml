<workflow-app xmlns="uri:oozie:workflow:0.4" name="mainworkflows_preprocessing">
	
	<parameters>
		<!-- import project related -->
		<property>
			<name>import_database_service_location</name>
			<value>$UNDEFINED$</value>
			<description>Database service (not WSDL) location URL</description>
		</property>
		<property>
			<name>import_database_dbname</name>
			<value>dnet_openaireplus_node0_t</value>
			<description>database name</description>
		</property>
		<!-- import datacite related, export datacite & wos related -->
		<property>
			<name>import_mdstore_service_location</name>
			<value>$UNDEFINED$</value>
			<description>MDStore service (not WSDL) location URL</description>
		</property>
		<property>
			<name>import_dataset_mdstore_id</name>
			<value>$UNDEFINED$</value>
			<description>dataset MDStore identifier</description>
		</property>
		<property>
			<name>import_wos_mdstore_id</name>
			<value>$UNDEFINED$</value>
			<description>WoS MDStore identifier</description>
		</property>
		<!-- import content related -->
		<!-- currently disabled, input_document_content property is handled as input holding DocumentContent datastore -->
		<property>
			<name>import_content_object_store_location</name>
			<value>$UNDEFINED$</value>
			<description>object store service location required for content retrieval</description>
		</property>
		<property>
			<name>import_content_lookup_service_location</name>
			<value>$UNDEFINED$</value>
			<description>lookup service location required for content retrieval, finding object store id based on repository id</description>
		</property>
		<property>
			<name>import_content_wos_plaintext_objectstores_csv</name>
			<value>$UNDEFINED$</value>
			<description>CSV list of objectstore ids to be approved during WoS plaintext import.</description>
		</property>
		<property>
			<name>import_content_datacite_objectstores_csv</name>
			<value>$UNDEFINED$</value>
			<description>CSV list of objectstore ids to be approved during datacite import.</description>
		</property>
		<!-- import content mime types -->
		<property>
			<name>import_content_mimetypes_pdf_csv</name>
			<value>pdf,application/pdf</value>
			<description>pdf mime types</description>
		</property>
		<property>
			<name>import_content_mimetypes_text_csv</name>
			<value>text,text/plain</value>
			<description>text mime types</description>
		</property>
		<property>
			<name>import_content_mimetypes_xml_pmc_csv</name>
			<value>xml</value>
			<description>xml pmc types</description>
		</property>
		<property>
			<name>import_content_mimetypes_wos_text_csv</name>
			<value>file::WoS</value>
			<description>WoS mime types</description>
		</property>
		<!-- import timeouts related -->
		<property>
			<name>import_resultset_client_read_timeout</name>
			<value>60000</value>
			<description>resultset client read timeout</description>
		</property>
		<property>
			<name>import_content_connection_timeout</name>
			<value>60000</value>
			<description>import content connection timeout</description>
		</property>
		<property>
			<name>import_content_read_timeout</name>
			<value>60000</value>
			<description>import content read timeout</description>
		</property>
		<!-- metadata extraction related -->
		<property>
			<name>metadataextraction_excluded_ids</name>
			<value>$UNDEFINED$</value>
			<description>list of content identifiers excluded from metadataextraction processing</description>
		</property>
		<property>
			<name>metadataextraction_default_cache_location</name>
			<description>metadata extraction cache location, path pointing to root cache directory holding meta.json file</description>
		</property>
		
		<!-- export related -->
		<property>
			<name>export_action_hbase_table_name</name>
			<description>action manager hbase table name</description>
		</property>
		<property>
			<name>export_action_hbase_table_initialize</name>
			<description>flag indicating input table should be initialized</description>
		</property>
		<!-- action set id properties -->
		<property>
			<name>export_action_set_id</name>
			<value>$UNDEFINED$</value>
			<description>action-set identifier of exported data</description>
		</property>
		<property>
			<name>export_action_set_id_document_referencedProjects</name>
			<value>$UNDEFINED$</value>
			<description>document_referencedProjects action-set identifier of exported data</description>
		</property>
		<property>
			<name>export_action_set_id_document_referencedDatasets</name>
			<value>$UNDEFINED$</value>
			<description>document_referencedDatasets action-set identifier of exported data</description>
		</property>
		<property>
			<name>export_action_set_id_entity_wos</name>
			<description>action-set identifier of exported data containing wos entities</description>
		</property>
		<property>
			<name>export_action_set_id_entity_dataset</name>
			<description>action-set identifier of exported data containing dataset entities</description>
		</property>
		<property>
			<name>export_action_hbase_remote_zookeeper_quorum</name>
			<value>$UNDEFINED$</value>
			<description>external hbase zookeeper quorum, set to empty value by default which means data will be exported to local hbase instance</description>
		</property>
		<property>
			<name>export_action_hbase_remote_zookeeper_clientport</name>
			<value>$UNDEFINED$</value>
			<description>external hbase zookeeper client port, required only whe zookeeper quorum property is set</description>
		</property>
	</parameters>

	<start to="import_forking" />

	<fork name="import_forking">
    	<path start="import_project"/>
		<path start="import_dataset"/>
    	<path start="content_importer_forking"/>
    </fork>
	
	<fork name="content_importer_forking">
    	<path start="wos_url_importer"/>
    	<path start="dataset_url_importer"/>
    </fork>

	<action name="wos_url_importer">
		<sub-workflow>
            <app-path>${wf:appPath()}/import_content_url</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/wos_url_import/working_dir</value>
                </property>
                <property>
					<name>objectstore_service_location</name>
					<value>${import_content_object_store_location}</value>
				</property>
				<property>
					<name>approved_objectstores_csv</name>
					<value>${import_content_wos_plaintext_objectstores_csv}</value>
				</property>
            	<property>
					<name>output_dir</name>
					<value>${workingDir}/wos_url_import/imported</value>
				</property>
				<property>
					<name>mimetypes_text_csv</name>
					<value>${import_content_mimetypes_wos_text_csv}</value>
				</property>
				<property>
					<name>resultset_client_read_timeout</name>
					<value>${import_resultset_client_read_timeout}</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="wos_import_plaintext" />
		<error to="fail" />
	</action>

	<action name="wos_import_plaintext">
		<sub-workflow>
            <app-path>${wf:appPath()}/import_plaintext</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/wos_import_plaintext/working_dir</value>
                </property>
                <property>
					<name>input</name>
					<value>${workingDir}/wos_url_import/imported/plaintext_url</value>
				</property>
				<property>
				    <name>content_connection_timeout</name>
				   <value>${import_content_connection_timeout}</value>
				</property>
				<property>
				    <name>content_read_timeout</name>
				   <value>${import_content_read_timeout}</value>
				</property>
            	<property>
					<name>output</name>
					<value>${workingDir}/wos_import_plaintext/imported</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="content_importer_joining" />
		<error to="fail" />
	</action>

	<action name="dataset_url_importer">
		<sub-workflow>
            <app-path>${wf:appPath()}/import_content_url</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/dataset_url_import/working_dir</value>
                </property>
                <property>
					<name>objectstore_service_location</name>
					<value>${import_content_object_store_location}</value>
				</property>
				<property>
					<name>approved_objectstores_csv</name>
					<value>${import_content_datacite_objectstores_csv}</value>
				</property>
				<property>
					<name>mimetypes_pdf_csv</name>
					<value>${import_content_mimetypes_pdf_csv}</value>
				</property>
				<property>
					<name>mimetypes_text_csv</name>
					<value>${import_content_mimetypes_text_csv}</value>
				</property>
				<property>
					<name>mimetypes_xml_pmc_csv</name>
					<value>${import_content_mimetypes_xml_pmc_csv}</value>
				</property>
				<property>
					<name>resultset_client_read_timeout</name>
					<value>${import_resultset_client_read_timeout}</value>
				</property>
            	<property>
					<name>output_dir</name>
					<value>${workingDir}/dataset_url_import/imported</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="dataset_import_urlbased_forking" />
		<error to="fail" />
	</action>

	<fork name="dataset_import_urlbased_forking">
    	<path start="dataset_import_plaintext"/>
    	<path start="dataset_import_plaintext_pmc"/>
		<path start="metadataextraction_cached"/>
    </fork>

	<action name="dataset_import_plaintext">
		<sub-workflow>
            <app-path>${wf:appPath()}/import_plaintext</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/dataset_import_plaintext/working_dir</value>
                </property>
                <property>
					<name>input</name>
					<value>${workingDir}/dataset_url_import/imported/plaintext_url</value>
				</property>
				<property>
				    <name>content_connection_timeout</name>
				   <value>${import_content_connection_timeout}</value>
				</property>
				<property>
				    <name>content_read_timeout</name>
				   <value>${import_content_read_timeout}</value>
				</property>
            	<property>
					<name>output</name>
					<value>${workingDir}/dataset_import_plaintext/imported</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="dataset_import_urlbased_joining" />
		<error to="fail" />
	</action>

	<action name="dataset_import_plaintext_pmc">
		<sub-workflow>
            <app-path>${wf:appPath()}/import_plaintext</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/import_plaintext_pmc/working_dir</value>
                </property>
                <property>
					<name>input</name>
					<value>${workingDir}/dataset_url_import/imported/xml_pmc_url</value>
				</property>
				<property>
				    <name>content_connection_timeout</name>
				   <value>${import_content_connection_timeout}</value>
				</property>
				<property>
				    <name>content_read_timeout</name>
				   <value>${import_content_read_timeout}</value>
				</property>
            	<property>
					<name>output</name>
					<value>${workingDir}/import_plaintext_pmc/imported</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="import_pmc" />
		<error to="fail" />
	</action>
	
	<action name="import_pmc">
		<sub-workflow>
            <app-path>${wf:appPath()}/import_pmc</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/import_pmc/working_dir</value>
                </property>
                <property>
					<name>input_document_nlm</name>
					<value>${workingDir}/import_plaintext_pmc/imported</value>
				</property>
            	<property>
					<name>output_document_plaintext</name>
					<value>${workingDir}/import_pmc/imported</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="dataset_import_urlbased_joining" />
		<error to="fail" />
	</action>

	<action name="metadataextraction_cached">
		<sub-workflow>
            <app-path>${wf:appPath()}/metadataextraction_cached</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/metadataextraction_cached/working_dir</value>
                </property>
            	<property>
                    <name>input</name>
                    <value>${workingDir}/dataset_url_import/imported/content_url</value>
                </property>
                <property>
                    <name>excluded_ids</name>
                    <value>${metadataextraction_excluded_ids}</value>
                </property>
                <property>
                    <name>default_cache_location</name>
                    <value>${metadataextraction_default_cache_location}</value>
                </property>
                <property>
                    <name>mapred_max_split_size</name>
                    <value>10000</value>
                </property>
                <property>
				    <name>content_connection_timeout</name>
				   <value>${import_content_connection_timeout}</value>
				</property>
				<property>
				    <name>content_read_timeout</name>
				   <value>${import_content_read_timeout}</value>
				</property>
            	<property>
					<name>output_root</name>
					<value>${workingDir}/metadataextraction_cached/out</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="dataset_import_urlbased_joining" />
		<error to="fail" />
	</action>

	<join name="dataset_import_urlbased_joining" to="transformers_common_union_plaintext_merge_outputs"/>

 	<!-- merging document text datastores: 
    	1) retrieved directly from objectstore 
    	2) generated by metadataextraction 
    	3) imported from PMC XMLs -->
	<action name="transformers_common_union_plaintext_merge_outputs">
		<sub-workflow>
            <app-path>${wf:appPath()}/transformers_common_union3</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
					<name>input_a</name>
					<value>${workingDir}/dataset_import_plaintext/imported</value>
				</property>
				<property>
					<name>input_b</name>
					<value>${workingDir}/metadataextraction_cached/out/plaintext</value>
				</property>
				<property>
					<name>input_c</name>
					<value>${workingDir}/import_pmc/imported</value>
				</property>
				<property>
					<name>output</name>
					<value>${workingDir}/dataset_plaintext</value>
				</property>
				<property>
					<name>schema</name>
					<value>eu.dnetlib.iis.metadataextraction.schemas.DocumentText</value>
				</property>
            </configuration>
        </sub-workflow>
		<ok to="content_importer_joining"/>
		<error to="fail" />
	</action>

	<join name="content_importer_joining" to="import_joining"/>

	<action name="import_project">
		<sub-workflow>
            <app-path>${wf:appPath()}/import_project</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/import_project/working_dir</value>
                </property>
                <property>
					<name>input_database_service_location</name>
					<value>${import_database_service_location}</value>
				</property>
				<property>
					<name>input_database_name</name>
					<value>${import_database_dbname}</value>
				</property>
				<property>
					<name>resultset_client_read_timeout</name>
					<value>${import_resultset_client_read_timeout}</value>
				</property>
            	<property>
					<name>output_dir</name>
					<value>${workingDir}/import_project/imported</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="import_joining" />
		<error to="fail" />
	</action>

	<action name="import_dataset">
		<sub-workflow>
            <app-path>${wf:appPath()}/import_dataset</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/import_dataset/working_dir</value>
                </property>
                <property>
					<name>input_mdstore_service_location</name>
					<value>${import_mdstore_service_location}</value>
				</property>
				<property>
					<name>input_mdstore_id</name>
					<value>${import_dataset_mdstore_id}</value>
				</property>
				<property>
					<name>resultset_client_read_timeout</name>
					<value>${import_resultset_client_read_timeout}</value>
				</property>
            	<property>
					<name>output_dir</name>
					<value>${workingDir}/import_dataset/imported</value>
				</property>
			</configuration>
        </sub-workflow>
		<ok to="import_joining" />
		<error to="fail" />
	</action>

	<join name="import_joining" to="referenceextraction_forking"/>
	
	<fork name="referenceextraction_forking">
		<path start="referenceextraction_dataset"/>
    	<path start="referenceextraction_project"/>
    </fork>
	
	<action name="referenceextraction_dataset">
	    <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_dataset</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_dataset/working_dir</value>
                </property>
            	<property>
					<name>input_document_text</name>
					<value>${workingDir}/dataset_plaintext</value>
				</property>
				<property>
					<name>input_dataset</name>
					<value>${workingDir}/import_dataset/imported</value>
				</property>
				<property>
					<name>output_document_to_dataset</name>
					<value>${workingDir}/referenceextraction_dataset/document_datasets</value>
				</property>
            </configuration>
        </sub-workflow>
		<ok to="referenceextraction_joining"/>
		<error to="fail" />
    </action>
	
	<action name="referenceextraction_project">
	    <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_project</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_project/working_dir</value>
                </property>
            	<property>
					<name>input_document_text</name>
					<value>${workingDir}/wos_import_plaintext/imported</value>
				</property>
				<property>
					<name>input_project</name>
					<value>${workingDir}/import_project/imported</value>
				</property>
				<property>
					<name>output_document_to_project</name>
					<value>${workingDir}/referenceextraction_project/document_projects</value>
				</property>
            </configuration>
        </sub-workflow>
		<ok to="referenceextraction_joining"/>
		<error to="fail" />
    </action>
    
    <join name="referenceextraction_joining" to="transformers_export_document_producer"/>
    
    <!-- this node is required due to the PIG limitation 
    	disallowing empty directories as input avro storages -->
    <action name="transformers_export_document_producer">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
			<!-- The data generated by this node is deleted in this section -->
			<prepare>
				<delete path="${nameNode}${workingDir}/producer" />
				<mkdir path="${nameNode}${workingDir}/producer" />
			</prepare>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
            </configuration>
            <!-- This is simple wrapper for the Java code -->
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<!-- The business Java code that gets to be executed -->
			<arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
			<!-- Specification of the output ports -->
            <arg>-C{extracted_document_metadata,
				eu.dnetlib.iis.metadataextraction.schemas.ExtractedDocumentMetadata,
				eu/dnetlib/iis/common/data/empty.json}</arg>
            <arg>-C{citation,
				eu.dnetlib.iis.citationmatching.schemas.Citation,
				eu/dnetlib/iis/common/data/empty.json}</arg>
            <arg>-C{document_to_project,
				eu.dnetlib.iis.referenceextraction.project.schemas.DocumentToProject,
				eu/dnetlib/iis/common/data/empty.json}</arg>
            <arg>-C{document_to_dataset,
				eu.dnetlib.iis.referenceextraction.dataset.schemas.DocumentToDataSet,
				eu/dnetlib/iis/common/data/empty.json}</arg>
			<arg>-C{document_to_research_initiative,
				eu.dnetlib.iis.referenceextraction.researchinitiative.schemas.DocumentToConceptId,
				eu/dnetlib/iis/common/data/empty.json}</arg>
            <arg>-C{document_to_document_clusters,
				eu.dnetlib.iis.documentsclustering.schemas.DocumentToDocumentClusters,
				eu/dnetlib/iis/common/data/empty.json}</arg>    
            <arg>-C{document_to_document_classes,
				eu.dnetlib.iis.documentsclassification.schemas.DocumentToDocumentClasses,
				eu/dnetlib/iis/common/data/empty.json}</arg>    
            <arg>-C{document_to_document_statistics,
				eu.dnetlib.iis.statistics.schemas.DocumentToDocumentStatistics,
				eu/dnetlib/iis/common/data/empty.json}</arg>    
            <arg>-C{document_with_website_usage_similarities,
				eu.dnetlib.iis.websiteusage.schemas.DocumentsWithWebsiteUsageSimilarities,
				eu/dnetlib/iis/common/data/empty.json}</arg>
			<!-- this one is required by dataset id generator, it is impossible to check
			existing dataset records therefore generating empty datastore -->	
			<arg>-C{dataset_existing_id,
				eu.dnetlib.iis.importer.schemas.DocumentId,
				eu/dnetlib/iis/common/data/empty.json}</arg>
			<!-- this one is required by WoS document exporter, it is impossible to check
			existing WoS publications therefore generating empty datastore -->	
			<arg>-C{document_existing_meta,
				eu.dnetlib.iis.importer.schemas.DocumentMetadata,
				eu/dnetlib/iis/common/data/empty.json}</arg>
			<!-- All input and output ports have to be bound to paths in HDFS -->
            <arg>-Oextracted_document_metadata=${workingDir}/producer/extracted_document_metadata</arg>
            <arg>-Ocitation=${workingDir}/producer/citation</arg>
            <arg>-Odocument_to_project=${workingDir}/producer/document_to_project</arg>
            <arg>-Odocument_to_dataset=${workingDir}/producer/document_to_dataset</arg>
            <arg>-Odocument_to_research_initiative=${workingDir}/producer/document_to_research_initiative</arg>
            <arg>-Odocument_to_document_clusters=${workingDir}/producer/document_to_document_clusters</arg>
            <arg>-Odocument_to_document_classes=${workingDir}/producer/document_to_document_classes</arg>
            <arg>-Odocument_to_document_statistics=${workingDir}/producer/document_to_document_statistics</arg>
            <arg>-Odocument_with_website_usage_similarities=${workingDir}/producer/document_with_website_usage_similarities</arg>
            <arg>-Odataset_existing_id=${workingDir}/producer/dataset_existing_id</arg>
            <arg>-Odocument_existing_meta=${workingDir}/producer/document_existing_meta</arg>
        </java>
        <ok to="transformers_export_document"/>
        <error to="fail"/>
    </action>
    
    <action name="transformers_export_document">
	    <sub-workflow>
            <app-path>${wf:appPath()}/transformers_export_document</app-path>
            <propagate-configuration/>
            <configuration>
				<property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_export_document/working_dir</value>
                </property>
                <!-- real input datastores -->
				<property>
					<name>input_document_to_project</name>
					<value>${workingDir}/referenceextraction_project/document_projects</value>
				</property>
				<property>
					<name>input_document_to_dataset</name>
					<value>${workingDir}/referenceextraction_dataset/document_datasets</value>
				</property>
				<!-- fake input datastores -->
				<property>
                    <name>input_document_to_research_initiative</name>
                    <value>${workingDir}/producer/document_to_research_initiative</value>
                </property>
				<property>
					<name>input_extracted_document_metadata</name>
					<value>${workingDir}/producer/extracted_document_metadata</value>
				</property>
				<property>
					<name>input_citation</name>
					<value>${workingDir}/producer/citation</value>
				</property>
				<property>
					<name>input_document_to_document_statistics</name>
					<value>${workingDir}/producer/document_to_document_statistics</value>
				</property>
				<property>
					<name>input_document_to_document_clusters</name>
					<value>${workingDir}/producer/document_to_document_clusters</value>
				</property>
				<property>
					<name>input_document_to_document_classes</name>
					<value>${workingDir}/producer/document_to_document_classes</value>
				</property>
				<property>
					<name>input_document_with_website_usage_similarities</name>
					<value>${workingDir}/producer/document_with_website_usage_similarities</value>
				</property>
				<!-- output datastore -->
				<property>
					<name>output_document_with_inferenced_data</name>
					<value>${workingDir}/exported/document_with_inferenced_data</value>
				</property>
            </configuration>
        </sub-workflow>
		<ok to="export_actionmanager"/>
		<error to="fail" />
    </action>
    
  	<action name="export_actionmanager">
		<sub-workflow>
            <app-path>${wf:appPath()}/export_actionmanager</app-path>
            <propagate-configuration/>
            <configuration>
            	<property>
                    <name>workingDir</name>
                    <value>${workingDir}/export_actionmanager/working_dir</value>
                </property>
            	<property>
					<name>input_document</name>
					<value>${workingDir}/exported/document_with_inferenced_data</value>
				</property>
				<property>
					<name>action_hbase_table_name</name>
					<value>${export_action_hbase_table_name}</value>
				</property>
				<property>
					<name>action_hbase_table_initialize</name>
					<value>${export_action_hbase_table_initialize}</value>
				</property>
				<property>
					<name>action_set_id</name>
					<value>${export_action_set_id}</value>
				</property>
				<property>
					<name>action_set_id_document_referencedProjects</name>
					<value>${export_action_set_id_document_referencedProjects}</value>
				</property>
				<property>
					<name>action_set_id_document_referencedDatasets</name>
					<value>${export_action_set_id_document_referencedDatasets}</value>
				</property>
				<property>
					<name>action_hbase_remote_zookeeper_quorum</name>
					<value>${export_action_hbase_remote_zookeeper_quorum}</value>
				</property>
				<property>
					<name>action_hbase_remote_zookeeper_clientport</name>
					<value>${export_action_hbase_remote_zookeeper_clientport}</value>
				</property>
            </configuration>
        </sub-workflow>
		<ok to="export_entities_forking"/>
		<error to="fail" />
	</action>
 
 	<fork name="export_entities_forking">
    	<path start="transformers_export_identifier_referenceddatasets"/>
    	<path start="transformers_export_identifier_document_to_project"/>
    </fork>
 
 	<!-- dataset entities export section -->
 	<action name="transformers_export_identifier_referenceddatasets">
	    <sub-workflow>
            <app-path>${wf:appPath()}/transformers_export_identifier_referenceddatasets</app-path>
            <propagate-configuration/>
            <configuration>
				<property>
                    <name>workingDir</name>
                    <value>${workingDir}/export_identifier_referenceddatasets/working_dir</value>
                </property>
                <property>
					<name>input_document_id</name>
					<!-- this is generated empty datastore -->
					<value>${workingDir}/producer/dataset_existing_id</value>
				</property>
				<property>
					<name>input_document_with_inferenced_data</name>
					<value>${workingDir}/exported/document_with_inferenced_data</value>
				</property>
				<property>
					<name>output_identifier</name>
					<value>${workingDir}/identifier/datasets</value>
				</property>
            </configuration>
        </sub-workflow>
        <ok to="exporter-dataset-entities"/>
		<error to="fail" />
    </action>
 
 	<action name="exporter-dataset-entities">
		<java>
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
			</configuration>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.wf.export.actionmanager.entity.dataset.DatasetExporterProcess</arg>
			<arg>-Iinput=${workingDir}/identifier/datasets</arg>
			
			<arg>-Pexport.entity.mdstore.service.location=${import_mdstore_service_location}</arg>
			<arg>-Pexport.entity.mdstore.id=${import_dataset_mdstore_id}</arg>
			<arg>-Pexport.action.setid=${export_action_set_id_entity_dataset}</arg>
			<arg>-Pexport.action.hbase.table.name=${export_action_hbase_table_name}</arg>
			<arg>-Pexport.action.hbase.remote.zookeeper.quorum=${export_action_hbase_remote_zookeeper_quorum}</arg>
			<arg>-Pexport.action.hbase.remote.zookeeper.clientport=${export_action_hbase_remote_zookeeper_clientport}</arg>
			<arg>-Pexport.action.hbase.table.initialize=${export_action_hbase_table_initialize}</arg>
		</java>
		<ok to="export_entities_joining" />
		<error to="fail" />
	</action>
    <!-- end of dataset entities export section -->
    
    <!-- WoS entities export section -->
 	<action name="transformers_export_identifier_document_to_project">
	    <sub-workflow>
            <app-path>${wf:appPath()}/transformers_export_identifier_document_to_project</app-path>
            <propagate-configuration/>
            <configuration>
				<property>
                    <name>workingDir</name>
                    <value>${workingDir}/export_identifier_documents/working_dir</value>
                </property>
                <property>
					<name>input_document_to_project</name>
					<value>${workingDir}/referenceextraction_project/document_projects</value>
				</property>
				<property>
					<name>output_identifier</name>
					<value>${workingDir}/identifier/documents</value>
				</property>
            </configuration>
        </sub-workflow>
        <ok to="exporter-document-entities"/>
		<error to="fail" />
    </action>
 
 	<action name="exporter-document-entities">
		<java>
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
			</configuration>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.wf.export.actionmanager.entity.document.DocumentExporterProcess</arg>
			<arg>-Iinput=${workingDir}/identifier/documents</arg>
			
			<arg>-Pexport.entity.mdstore.service.location=${import_mdstore_service_location}</arg>
			<arg>-Pexport.entity.mdstore.id=${import_wos_mdstore_id}</arg>
			<arg>-Pexport.action.setid=${export_action_set_id_entity_wos}</arg>
			<arg>-Pexport.action.hbase.table.name=${export_action_hbase_table_name}</arg>
			<arg>-Pexport.action.hbase.remote.zookeeper.quorum=${export_action_hbase_remote_zookeeper_quorum}</arg>
			<arg>-Pexport.action.hbase.remote.zookeeper.clientport=${export_action_hbase_remote_zookeeper_clientport}</arg>
			<arg>-Pexport.action.hbase.table.initialize=${export_action_hbase_table_initialize}</arg>
		</java>
		<ok to="export_entities_joining" />
		<error to="fail" />
	</action>
    <!-- end of WoS entities export section -->
    
    <join name="export_entities_joining" to="end"/>
    
	<kill name="fail">
		<message>Unfortunately, the process failed -- error message:
			[${wf:errorMessage(wf:lastErrorNode())}]</message>
	</kill>
	<end name="end" />
</workflow-app>
