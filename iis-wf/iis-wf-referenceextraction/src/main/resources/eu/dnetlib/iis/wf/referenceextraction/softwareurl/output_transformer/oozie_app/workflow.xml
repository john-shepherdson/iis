<workflow-app xmlns="uri:oozie:workflow:0.4" name="transformers_export_softwareurl">

    <parameters>
        <property>
            <name>input</name>
        </property>
        <property>
            <name>output</name>
        </property>
        <property>
            <name>output_report_root_path</name>
            <description>base directory for storing reports</description>
        </property>
    </parameters>

    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
        </configuration>
    </global>

    <start to="generate-schema" />

    <action name="generate-schema">
        <java>
            <main-class>eu.dnetlib.iis.common.javamapreduce.hack.AvroSchemaGenerator</main-class>
            <arg>eu.dnetlib.iis.referenceextraction.softwareurl.schemas.DocumentToSoftwareUrl</arg>
            <arg>eu.dnetlib.iis.export.schemas.DocumentToSoftwareUrls</arg>
            <capture-output />
        </java>
        <ok to="transformer" />
        <error to="fail" />
    </action>

    <action name="transformer">
        <pig>
            <!-- The data generated by this node is deleted in this section -->
            <prepare>
                <delete path="${nameNode}${output}" />
            </prepare>
            <configuration>
                <property>
                    <name>oozie.action.external.stats.write</name>
                    <value>true</value>
                </property>
            </configuration>

            <!-- Path to PIG script the workflow executes. -->
            <script>lib/scripts/transformer.pig</script>

            <param>input=${input}</param>
            <param>schema_input=${wf:actionData('generate-schema')['eu.dnetlib.iis.referenceextraction.softwareurl.schemas.DocumentToSoftwareUrl']}</param>

            <param>output=${output}</param>
            <param>schema_output=${wf:actionData('generate-schema')['eu.dnetlib.iis.export.schemas.DocumentToSoftwareUrls']}</param>
        </pig>
        <ok to="report" />
        <error to="fail" />
    </action>
    
    <action name="report">
         <java>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.report.PigCountersReportGenerator</arg>
            <arg>-PpigCounters=${hadoop:counters('transformer')}</arg>
            <arg>-Preport.export.referenceExtraction.docSoftwareUrlReferences={documentToSoftwareUrl.MAP_INPUT_RECORDS}</arg>
            <arg>-Preport.export.referenceExtraction.docsWithAtLeastOneSoftwareUrl={RECORD_WRITTEN}</arg>
            <arg>-Oreport=${output_report_root_path}/doc-software-url</arg>
        </java>
        <ok to="end" />
        <error to="fail" />
    </action>
    
    
    <kill name="fail">
        <message>Unfortunately, the workflow failed -- error message:
            [${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>
    <end name="end" />
</workflow-app>
