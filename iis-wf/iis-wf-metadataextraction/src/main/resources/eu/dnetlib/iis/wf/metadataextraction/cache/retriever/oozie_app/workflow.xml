<workflow-app xmlns="uri:oozie:workflow:0.4" name="metadataextraction_cache_retriever">

    <parameters>
        <property>
            <name>match_content_with_metadata</name>
            <value>true</value>
            <description>flag indicating contents should be filtered and their identifiers should be deduplicated against metadata entries retrieved from InformationSpace.
                This way only contents having metadata representation will be processed.
                To be disabled when processing new contents which metadata is not available in hbase or when original identifiers should be preserved (contents will not be filtered as well).
            </description>
        </property>
        <!-- import metadata related -->
        <property>
            <name>hbase_dump_location</name>
            <value>$UNDEFINED$</value>
            <description>InformationSpace HBase dump location, usually points to remote cluster HDFS location. Required when ${match_content_with_metadata} is set to true.</description>
        </property>
        <property>
            <name>distcp_memory_mb</name>
            <value>6144</value>
            <description>memory for distcp action copying InfoSpace dump from remote cluster</description>
        </property>
        <property>
            <name>inference_provenance_blacklist</name>
            <value>iis::.*</value>
            <description>list of blacklisted inference provenance which sould not be taken into account by importer, skipped when set to $UNDEFINED$</description>
        </property>
        <property>
            <name>trust_level_threshold</name>
            <value>$UNDEFINED$</value>
            <description>trust level threshold represented as float value, ignored when set to $UNDEFINED$ value</description>
        </property>
        <property>
            <name>merge_body_with_updates</name>
            <value>false</value>
            <description>flag indicating Oaf objects strored in body qualifier should be merged with Oaf objects stored in update qualifier</description>
        </property>
        <!-- import content related -->
        <property>
            <name>objectstore_service_location</name>
            <description>object store service location required for content retrieval</description>
        </property>
        <property>
            <name>approved_objectstores_csv</name>
            <value>$UNDEFINED$</value>
            <description>CSV list of object stores identifiers to be processed</description>
        </property>
        <property>
            <name>mimetypes_pdf</name>
            <value>pdf,application/pdf</value>
            <description>pdf mime types</description>
        </property>
        <property>
            <name>mimetypes_html</name>
            <value>text/html</value>
            <description>html mime types</description>
        </property>
        <property>
            <name>mimetypes_xml_pmc</name>
            <value>xml</value>
            <description>xml pmc types</description>
        </property>
        <property>
            <name>mimetypes_wos</name>
            <value>file::WoS</value>
            <description>WoS types</description>
        </property>
        <!-- import timeouts related -->
        <property>
            <name>resultset_client_read_timeout</name>
            <value>60000</value>
            <description>resultset client read timeout (expressed in milliseconds)</description>
        </property>
        <property>
            <name>resultset_client_connection_timeout</name>
            <value>60000</value>
            <description>resultset client connection timeout (expressed in milliseconds)</description>
        </property>
        <property>
            <name>content_connection_timeout</name>
            <value>60000</value>
            <description>import content connection timeout (expressed in milliseconds)</description>
        </property>
        <property>
            <name>content_read_timeout</name>
            <value>60000</value>
            <description>import content read timeout (expressed in milliseconds)</description>
        </property>
        <property>
            <name>text_xml_max_file_size_mb</name>
            <value>2</value>
            <description>maximum allowed xml or text file size in Megabytes</description>
        </property>
        <property>
            <name>ingest_pmc_cache_location</name>
            <description>PMC ingestion HDFS cache location</description>
        </property>
        <!-- metadata extraction related -->
        <property>
            <name>metadataextraction_excluded_checksums</name>
            <value>$UNDEFINED$</value>
            <description>list of content checksums excluded from metadataextraction processing</description>
        </property>
        <property>
            <name>pdf_max_file_size_mb</name>
            <value>100</value>
            <description>maximum allowed pdf file size in Megabytes</description>
        </property>
        <property>
            <name>metadataextraction_cache_location</name>
            <description>metadata extraction HDFS cache location</description>
        </property>
        <!-- metadata import output subdirectory names -->
        <property>
            <name>metadataimport_output_name_document_meta</name>
            <value>docmeta</value>
            <description>metadata import docmeta output subdirectory name</description>
        </property>
        <property>
            <name>metadataimport_output_name_dedup_mapping</name>
            <value>dedupmapping</value>
            <description>metadata import deduplication mapping output subdirectory name</description>
        </property>
        <!-- output location -->
        <property>
            <name>output_remote_location</name>
            <description>remote cluster output location where plaintexts should be distcped</description>
        </property>
        <property>
            <name>output_report_root_path</name>
            <value>${workingDir}/report</value>
        </property>
        <property>
            <name>reports_external_path</name>
            <value>$UNDEFINED$</value>
            <description>directory for storing reports from different executions of the workflow</description>
        </property>
        <!-- working directory related -->
        <property>
            <name>execution_environment</name>
            <value>cache_retriever</value>
            <description>execution environment used for workingDir creation</description>
        </property>
        <property>
            <name>workingDir</name>
            <value>/user/${user.name}/iis/working_dirs/${execution_environment}</value>
            <description>working directory</description>
        </property>
    </parameters>

    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
        </configuration>
    </global>

    <start to="init-workingDir" />

    <action name="init-workingDir">
        <fs>
            <delete path="${nameNode}${workingDir}" />
            <mkdir path="${nameNode}${workingDir}" />
        </fs>
        <ok to="copy-version" />
        <error to="fail" />
    </action>

    <action name="copy-version">
        <distcp xmlns="uri:oozie:distcp-action:0.2">
            <arg>${wf:appPath()}/version.properties</arg>
            <arg>${nameNode}${workingDir}</arg>
        </distcp>
        <ok to="decision-match_content_with_metadata" />
        <error to="fail" />
    </action>

    <decision name="decision-match_content_with_metadata">
        <switch>
            <case to="distcp_hbase_dump">${match_content_with_metadata eq "true"}</case>
            <default to="input_id_mapping-path-setter" />
        </switch>
    </decision>

    <!-- importing hbase dump from remote cluster -->
    <action name="distcp_hbase_dump">
        <distcp xmlns="uri:oozie:distcp-action:0.2">
            <arg>-Dmapreduce.map.memory.mb=${distcp_memory_mb}</arg>
            <arg>-pb</arg>
            <arg>${hbase_dump_location}</arg>
            <arg>${nameNode}${workingDir}/hbase_dump</arg>
        </distcp>
        <ok to="import_infospace" />
        <error to="fail" />
    </action>

    <action name="import_infospace">
        <sub-workflow>
            <app-path>${wf:appPath()}/import_infospace</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/import_infospace/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/hbase_dump</value>
                </property>
                <property>
                    <name>approved_columnfamilies_csv</name>
                    <value>result,resultResult_dedup_merges</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/output_metadataimport_root</value>
                </property>
                <!-- subdirectory names -->
                <property>
                    <name>output_name_document_meta</name>
                    <value>${metadataimport_output_name_document_meta}</value>
                </property>
                <property>
                    <name>output_name_dedup_mapping</name>
                    <value>${metadataimport_output_name_dedup_mapping}</value>
                </property>
                <!-- all the other properties are autmatically propagated -->
            </configuration>
        </sub-workflow>
        <ok to="purge_hbase_dump" />
        <error to="fail" />
    </action>

    <action name="purge_hbase_dump">
        <fs>
            <delete path="${nameNode}${workingDir}/hbase_dump" />
        </fs>
        <ok to="transformers-idextractor" />
        <error to="fail" />
    </action>
    <!-- end of importing InformationSpace -->

    <action name="transformers-idextractor">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_idextractor</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_idextractor/working_dir</value>
                </property>
                <property>
                    <name>input_document_metadata</name>
                    <value>${workingDir}/output_metadataimport_root/${metadataimport_output_name_document_meta}</value>
                </property>
                <property>
                    <name>output_identifier</name>
                    <value>${workingDir}/transformers_idextractor/output</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="input_id_mapping-path-setter" />
        <error to="fail" />
    </action>

    <action name='input_id_mapping-path-setter'>
        <java>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.oozie.property.ConditionalPropertySetter</arg>
            <arg>-Pcondition=${match_content_with_metadata eq "true"}</arg>
            <arg>-PinCaseOfTrue=${workingDir}/output_metadataimport_root/${metadataimport_output_name_dedup_mapping}</arg>
            <arg>-PelseCase=$UNDEFINED$</arg>
            <capture-output />
        </java>
        <ok to="input_id-path-setter" />
        <error to="fail" />
    </action>

    <action name='input_id-path-setter'>
        <java>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.oozie.property.ConditionalPropertySetter</arg>
            <arg>-Pcondition=${match_content_with_metadata eq "true"}</arg>
            <arg>-PinCaseOfTrue=${workingDir}/transformers_idextractor/output</arg>
            <arg>-PelseCase=$UNDEFINED$</arg>
            <capture-output />
        </java>
        <ok to="import_content_url" />
        <error to="fail" />
    </action>

    <action name="import_content_url">
        <sub-workflow>
            <app-path>${wf:appPath()}/import_content_url</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/import_content_url/working_dir</value>
                </property>
                <property>
                    <name>input_id</name>
                    <value>${wf:actionData('input_id-path-setter')['result']}</value>
                </property>
                <property>
                    <name>input_id_mapping</name>
                    <value>${wf:actionData('input_id_mapping-path-setter')['result']}</value>
                </property>
                <property>
                    <name>output_root</name>
                    <value>${workingDir}/import_content_url/imported</value>
                </property>
                <property>
                    <name>output_name_pdf</name>
                    <value>pdf</value>
                </property>
                <property>
                    <name>output_name_html</name>
                    <value>html</value>
                </property>
                <property>
                    <name>output_name_xml_pmc</name>
                    <value>xmlpmc</value>
                </property>
                <property>
                    <name>output_name_wos</name>
                    <value>wos</value>
                </property>
                <!-- all the other properties are autmatically propagated -->
            </configuration>
        </sub-workflow>
        <ok to="import_urlbased_forking" />
        <error to="fail" />
    </action>

    <fork name="import_urlbased_forking">
        <path start="import_wos" />
        <path start="import_html" />
        <path start="ingest_pmc_cached" />
        <path start="metadata_extractor_cached" />
    </fork>

    <action name="import_wos">
        <sub-workflow>
            <app-path>${wf:appPath()}/import_plaintext</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/import_wos/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/import_content_url/imported/wos</value>
                </property>
                <property>
                    <name>max_file_size_mb</name>
                    <value>${text_xml_max_file_size_mb}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/plaintext_wos</value>
                </property>
                <property>
                    <name>output_report_relative_path</name>
                    <value>import_content_wos</value>
                </property>
                <property>
                    <name>report_properties_prefix</name>
                    <value>import.content.wos</value>
                </property>
                <!-- all the other properties are autmatically propagated -->
            </configuration>
        </sub-workflow>
        <ok to="import_urlbased_joining" />
        <error to="fail" />
    </action>

    <!-- html import and plaintext ingestion section -->
    <action name="import_html">
        <sub-workflow>
            <app-path>${wf:appPath()}/import_plaintext</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/import_html/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/import_content_url/imported/html</value>
                </property>
                <property>
                    <name>max_file_size_mb</name>
                    <value>${text_xml_max_file_size_mb}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/import_html/imported</value>
                </property>
                <property>
                    <name>output_report_relative_path</name>
                    <value>import_content_html</value>
                </property>
                <property>
                    <name>report_properties_prefix</name>
                    <value>import.content.html</value>
                </property>
                <!-- all the other properties are autmatically propagated -->
            </configuration>
        </sub-workflow>
        <ok to="ingest_html_plaintext" />
        <error to="fail" />
    </action>

    <action name="ingest_html_plaintext">
        <sub-workflow>
            <app-path>${wf:appPath()}/ingest_html_plaintext</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/ingest_html_plaintext/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/import_html/imported</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/plaintext_html</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="import_urlbased_joining" />
        <error to="fail" />
    </action>
    <!-- end of html import and plaintext ingestion section -->
    
    <action name="ingest_pmc_cached">
        <sub-workflow>
            <app-path>${wf:appPath()}/metadataextraction_cache</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>metadata_extractor_app_name</name>
                    <value>ingest_pmc_metadata</value>
                </property>
                <property>
                    <name>cache_report_relative_path</name>
                    <value>import_ingestpmc_cache</value>
                </property>
                <property>
                    <name>cache_report_properties_prefix</name>
                    <value>import.ingestPmc</value>
                </property>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/ingest_pmc_metadata/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/import_content_url/imported/xmlpmc</value>
                </property>
                <property>
                    <name>max_file_size_mb</name>
                    <value>${text_xml_max_file_size_mb}</value>
                </property>
                <property>
                    <name>cache_location</name>
                    <value>${ingest_pmc_cache_location}</value>
                </property>
                <property>
                    <name>output_name_meta</name>
                    <value>meta</value>
                </property>
                <property>
                    <name>output_name_fault</name>
                    <value>fault</value>
                </property>
                <property>
                    <name>output_root</name>
                    <value>${workingDir}/ingest_pmc_metadata/out</value>
                </property>
                <!-- all the other properties are autmatically propagated -->
            </configuration>
        </sub-workflow>
        <ok to="import_urlbased_joining" />
        <error to="fail" />
    </action>

    <action name="metadata_extractor_cached">
        <sub-workflow>
            <app-path>${wf:appPath()}/metadataextraction_cache</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/metadata_extractor/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/import_content_url/imported/pdf</value>
                </property>
                <property>
                    <name>excluded_ids</name>
                    <value>${metadataextraction_excluded_checksums}</value>
                </property>
                <property>
                    <name>max_file_size_mb</name>
                    <value>${pdf_max_file_size_mb}</value>
                </property>
                <property>
                    <name>cache_location</name>
                    <value>${metadataextraction_cache_location}</value>
                </property>
                <property>
                    <name>output_name_meta</name>
                    <value>meta</value>
                </property>
                <property>
                    <name>output_name_fault</name>
                    <value>fault</value>
                </property>
                <property>
                    <name>output_root</name>
                    <value>${workingDir}/metadata_extractor/out</value>
                </property>
                <!-- all the other properties are autmatically propagated -->
            </configuration>
        </sub-workflow>
        <ok to="import_urlbased_joining" />
        <error to="fail" />
    </action>

    <join name="import_urlbased_joining" to="union_extracted_document_metadata" />

    <!-- merging extracted document metadata datastores (including new text field): 1) extracted from PDF documents 2) ingested from XML JATS documents -->
    <action name="union_extracted_document_metadata">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_common_union</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_common_union_extracted_document_metadata/working_dir</value>
                </property>
                <property>
                    <name>input_a</name>
                    <value>${workingDir}/ingest_pmc_metadata/out/meta</value>
                </property>
                <property>
                    <name>input_b</name>
                    <value>${workingDir}/metadata_extractor/out/meta</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/output_extracted_document_metadata</value>
                </property>
                <property>
                    <name>schema</name>
                    <value>eu.dnetlib.iis.metadataextraction.schemas.ExtractedDocumentMetadata</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_extracted_document_metadata_to_text" />
        <error to="fail" />
    </action>
    
    <action name="transformers_extracted_document_metadata_to_text">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_metadataextraction_documenttext</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_metadataextraction_documenttext/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/output_extracted_document_metadata</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/transformers_metadataextraction_documenttext/out</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_common_union_document_text" />
        <error to="fail" />
    </action>
    
    <!-- merging document text datastores: 1) extracted from PDF and XML documents 2) HTML plaintexts 3) WoS plaintexts -->
    <action name="transformers_common_union_document_text">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_common_union3</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_common_union_document_text/working_dir</value>
                </property>
                <property>
                    <name>input_a</name>
                    <value>${workingDir}/transformers_metadataextraction_documenttext/out</value>
                </property>
                <property>
                    <name>input_b</name>
                    <value>${workingDir}/plaintext_html</value>
                </property>
                <property>
                    <name>input_c</name>
                    <value>${workingDir}/plaintext_wos</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>schema</name>
                    <value>eu.dnetlib.iis.metadataextraction.schemas.DocumentText</value>
                </property>
                <property>
                    <name>output_report</name>
                    <value>${output_report_root_path}/document_text_union</value>
                </property>
                <property>
                    <name>union_count_report_key</name>
                    <value>processing.merging.documentText</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="distcp_output" />
        <error to="fail" />
    </action>
    
    <!-- TODO convert documenttext to desired format and update distcp input -->

    <action name="distcp_output">
        <distcp xmlns="uri:oozie:distcp-action:0.2">
            <arg>-Dmapreduce.map.memory.mb=${distcp_memory_mb}</arg>
            <arg>-pb</arg>
            <arg>-overwrite</arg>
            <arg>${nameNode}${workingDir}/transformers_common_union_document_text/out</arg>
            <arg>${output_remote_location}</arg>
        </distcp>
        <ok to="report-execution-times" />
        <error to="fail" />
    </action>

    <action name="report-execution-times">
        <java>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.report.OozieTimeReportGenerator</arg>
            <arg>-PjobId=${wf:id()}</arg>
            <arg>-PoozieServiceLoc=${oozieServiceLoc}</arg>
            <arg>-Preport.import.infoSpace.duration=import_infospace</arg>
            <arg>-Preport.import.content.url.duration=import_content_url</arg>
            <arg>-Preport.import.ingestPmc.duration=ingest_pmc_cached</arg>
            <arg>-Preport.import.metadataExtraction.duration=metadata_extractor_cached</arg>
            <arg>-Preport.export.distcp=distcp_output</arg>
            <arg>-Oreport=${output_report_root_path}/execution-times</arg>
        </java>
        <ok to="build-report" />
        <error to="fail" />
    </action>

    <action name="build-report">
        <sub-workflow>
            <app-path>${wf:appPath()}/report</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>working_dir</name>
                    <value>${workingDir}/report/working_dir</value>
                </property>
                <property>
                    <name>input_partial_reports</name>
                    <value>${workingDir}/report</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="end" />
        <error to="fail" />
    </action>
    
    <kill name="fail">
        <message>Unfortunately, the process failed -- error message:
            [${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>
    <end name="end" />
</workflow-app>
