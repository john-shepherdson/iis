<workflow-app xmlns="uri:oozie:workflow:0.4" name="metadataextraction_cache_builder">
	<parameters>
		<property>
			<name>objectstore_service_location</name>
			<description>object store service location required for content retrieval</description>
		</property>
		<property>
			<name>approved_objectstores_csv</name>
			<description>CSV list of object stores identifiers to be processed</description>
		</property>
		<property>
			<name>mimetypes_pdf</name>
			<value>pdf,application/pdf</value>
			<description>pdf mime types</description>
		</property>
		<property>
			<name>resultset_client_read_timeout</name>
			<value>60000</value>
			<description>resultset client read timeout (expressed in milliseconds)</description>
		</property>
		<property>
			<name>content_connection_timeout</name>
			<value>60000</value>
			<description>import content connection timeout (expressed in milliseconds)</description>
		</property>
		<property>
			<name>content_read_timeout</name>
			<value>60000</value>
			<description>import content read timeout (expressed in milliseconds)</description>
		</property>
		<property>
			<name>metadataextraction_excluded_checksums</name>
			<value>$UNDEFINED$</value>
			<description>list of content checksums excluded from metadataextraction processing</description>
		</property>
		<property>
			<name>max_file_size_mb</name>
			<value>500</value>
			<description>maximum allowed pdf file size in Megabytes</description>
		</property>
		<property>
			<name>zk_session_timeout</name>
			<value>60000</value>
			<description>zookeeper session timeout when handling locks (expressed in milliseconds)</description>
		</property>
		<property>
			<name>cache_location</name>
			<description>metadata extraction HDFS cache location.
				Directory with appropriate permisions has to be created in advance.
			</description>
		</property>
		<property>
			<name>remove_sideproducts</name>
			<value>true</value>
			<description>flag indicating whole working directory will be erased</description>
		</property>
	</parameters>

	<global>
		<job-tracker>${jobTracker}</job-tracker>
		<name-node>${nameNode}</name-node>
		<configuration>
			<property>
				<name>mapreduce.job.queuename</name>
				<value>${queueName}</value>
			</property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
			<property>
				<name>output_name_meta</name>
				<value>meta</value>
			</property>
			<property>
				<name>output_name_fault</name>
				<value>fault</value>
			</property>
		</configuration>
	</global>

	<start to="import_content_url" />

	<action name="import_content_url">
		<sub-workflow>
			<app-path>${wf:appPath()}/import_content_url</app-path>
			<propagate-configuration />
			<configuration>
				<property>
					<name>workingDir</name>
					<value>${workingDir}/import_content_url/working_dir</value>
				</property>
				<property>
					<name>output_root</name>
					<value>${workingDir}/import_content_url/imported</value>
				</property>
				<property>
					<name>mimetypes_text</name>
					<value>text,text/plain</value>
				</property>
				<property>
					<name>mimetypes_html</name>
					<value>text/html</value>
				</property>
				<property>
					<name>mimetypes_xml_pmc</name>
					<value>xml</value>
				</property>
				<property>
					<name>mimetypes_wos</name>
					<value>file::WoS</value>
				</property>
				<property>
					<name>output_name_pdf</name>
					<value>pdf</value>
				</property>
				<!-- all the other properties are autmatically propagated -->
			</configuration>
		</sub-workflow>
		<ok to="preprocessing" />
		<error to="fail" />
	</action>

	<action name="preprocessing">
		<sub-workflow>
			<app-path>${wf:appPath()}/transformers_metadataextraction_checksum_preprocessing</app-path>
			<propagate-configuration />
			<configuration>
				<property>
					<name>workingDir</name>
					<value>${workingDir}/preprocessing/working_dir</value>
				</property>
				<property>
					<name>input</name>
					<value>${workingDir}/import_content_url/imported/pdf</value>
				</property>
				<property>
					<name>output</name>
					<value>${workingDir}/preprocessing/output</value>
				</property>
			</configuration>
		</sub-workflow>
		<ok to="check_input_isempty" />
		<error to="fail" />
	</action>

	<action name="check_input_isempty">
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.utils.EmptyDatastoreVerifierProcess</arg>
			<arg>-Iinput=${workingDir}/preprocessing/output</arg>
			<capture-output />
		</java>
		<ok to="decision_is_intput_empty" />
		<error to="fail" />
	</action>

	<decision name="decision_is_intput_empty">
		<switch>
			<!-- skipping metadataextraction merging process -->
			<case to="get-existing-cache-id">${wf:actionData('check_input_isempty')['isEmpty'] eq "false"}</case>
			<default to="finalize" />
		</switch>
	</decision>

	<action name='get-existing-cache-id'>
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.cache.CacheMetadataManagingProcess</arg>
			<arg>-Pdefault_cache_location=${cache_location}</arg>
			<arg>-Pmode=read_current_id</arg>
			<capture-output />
		</java>
		<ok to="decision-is-cache-empty" />
		<error to="fail" />
	</action>

	<decision name="decision-is-cache-empty">
		<switch>
			<case to="metadata_extractor_on_full_input">${wf:actionData('get-existing-cache-id')['cache_id'] eq "$UNDEFINED$"}</case>
			<default to="transformer_metadataextraction_skip_extracted" />
		</switch>
	</decision>

	<!-- end of cache based processing block, cache was provided as an input -->
	<action name="transformer_metadataextraction_skip_extracted">
		<sub-workflow>
			<app-path>${wf:appPath()}/transformers_metadataextraction_skip_extracted</app-path>
			<propagate-configuration />
			<configuration>
				<property>
					<name>workingDir</name>
					<value>${workingDir}/transformers_metadataextraction_skip_extracted/working_dir</value>
				</property>
				<property>
					<name>input_document_content</name>
					<value>${workingDir}/preprocessing/output</value>
				</property>
				<property>
					<name>input_document_meta</name>
					<value>${cache_location}/${wf:actionData('get-existing-cache-id')['cache_id']}/meta</value>
				</property>
				<property>
					<name>output_document_content</name>
					<value>${workingDir}/transformers_metadataextraction_skip_extracted/tobeprocessed_content</value>
				</property>
			</configuration>
		</sub-workflow>
		<ok to="metadata_extractor_on_filtered_input" />
		<error to="fail" />
	</action>

	<action name="metadata_extractor_on_filtered_input">
		<sub-workflow>
			<app-path>${wf:appPath()}/metadata_extractor</app-path>
			<propagate-configuration />
			<configuration>
				<property>
					<name>workingDir</name>
					<value>${workingDir}/metadata_extractor/working_dir</value>
				</property>
				<property>
					<name>excluded_ids</name>
					<value>${metadataextraction_excluded_checksums}</value>
				</property>
				<property>
					<name>input</name>
					<value>${workingDir}/transformers_metadataextraction_skip_extracted/tobeprocessed_content</value>
				</property>
				<property>
					<name>output_root</name>
					<value>${workingDir}/metadata_extractor/output_root</value>
				</property>
				<!-- all the other properties are autmatically propagated -->
			</configuration>
		</sub-workflow>
		<ok to="check_metadataextraction_output_meta_isempty" />
		<error to="fail" />
	</action>

	<action name='check_metadataextraction_output_meta_isempty'>
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.utils.EmptyDatastoreVerifierProcess</arg>
			<arg>-Iinput=${workingDir}/metadata_extractor/output_root/meta</arg>
			<capture-output />
		</java>
		<ok to="decision-is-metadataextraction-output-empty" />
		<error to="fail" />
	</action>

	<decision name="decision-is-metadataextraction-output-empty">
		<switch>
			<!-- skipping metadataextraction merging process -->
			<case to="obtain-lock_for_merging">${wf:actionData('check_metadataextraction_output_meta_isempty')['isEmpty'] eq "false"}</case>
			<default to="finalize" />
		</switch>
	</decision>

	<action name="obtain-lock_for_merging">
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.lock.LockManagingProcess</arg>
			<arg>-Pzk_session_timeout=${zk_session_timeout}</arg>
			<arg>-Pnode_id=${cache_location}</arg>
			<arg>-Pmode=obtain</arg>
		</java>
		<ok to="get-new-cache-id_for_merging" />
		<error to="release-lock-and-fail" />
	</action>

	<action name='get-new-cache-id_for_merging'>
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.cache.CacheMetadataManagingProcess</arg>
			<arg>-Pdefault_cache_location=${cache_location}</arg>
			<arg>-Pmode=generate_new_id</arg>
			<capture-output />
		</java>
		<ok to="prepare_cache_for_merging" />
		<error to="release-lock-and-fail" />
	</action>

	<action name="prepare_cache_for_merging">
		<fs>
			<mkdir path="${nameNode}${cache_location}/${wf:actionData('get-new-cache-id_for_merging')['cache_id']}" />
		</fs>
		<ok to="transformers_common_union_meta_merge_cache" />
		<error to="release-lock-and-fail" />
	</action>

	<action name="transformers_common_union_meta_merge_cache">
		<sub-workflow>
			<app-path>${wf:appPath()}/transformers_common_union</app-path>
			<propagate-configuration />
			<configuration>
				<property>
					<name>input_a</name>
					<value>${cache_location}/${wf:actionData('get-existing-cache-id')['cache_id']}/meta</value>
				</property>
				<property>
					<name>input_b</name>
					<value>${workingDir}/metadata_extractor/output_root/meta</value>
				</property>
				<property>
					<name>output</name>
					<value>${cache_location}/${wf:actionData('get-new-cache-id_for_merging')['cache_id']}/meta</value>
				</property>
				<property>
					<name>schema</name>
					<value>eu.dnetlib.iis.metadataextraction.schemas.ExtractedDocumentMetadata</value>
				</property>
				<property>
					<name>combine_splits</name>
					<value>335544320</value>
				</property>
			</configuration>
		</sub-workflow>
		<ok to="write-new-cache-id_for_merging" />
		<error to="fail-merge_cache-temp_files_cleanup" />
	</action>

	<action name="fail-merge_cache-temp_files_cleanup">
		<fs>
			<delete path="${nameNode}${cache_location}/${wf:actionData('get-new-cache-id_for_merging')['cache_id']}" />
		</fs>
		<ok to="release-lock-and-fail" />
		<error to="release-lock-and-fail" />
	</action>

	<action name='write-new-cache-id_for_merging'>
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.cache.CacheMetadataManagingProcess</arg>
			<arg>-Pdefault_cache_location=${cache_location}</arg>
			<arg>-Pmode=write_id</arg>
			<arg>-Pid=${wf:actionData('get-new-cache-id_for_merging')['cache_id']}</arg>
			<capture-output />
		</java>
		<ok to="release-lock-and-end" />
		<error to="fail-merge_cache-temp_files_cleanup" />
	</action>

	<!-- end of cache based processing block, cache was provided as an input -->

	<!-- full input processing block, no cache was provided as an input -->
	<action name="metadata_extractor_on_full_input">
		<sub-workflow>
			<app-path>${wf:appPath()}/metadata_extractor</app-path>
			<propagate-configuration />
			<configuration>
				<property>
					<name>workingDir</name>
					<value>${workingDir}/metadata_extractor/working_dir</value>
				</property>
				<property>
					<name>excluded_ids</name>
					<value>${metadataextraction_excluded_checksums}</value>
				</property>
				<property>
					<name>input</name>
					<value>${workingDir}/preprocessing/output</value>
				</property>
				<property>
					<name>output_root</name>
					<value>${workingDir}/metadata_extractor/output_root</value>
				</property>
				<!-- all the other properties are autmatically propagated -->
			</configuration>
		</sub-workflow>
		<ok to="obtain-lock_for_initializing" />
		<error to="fail" />
	</action>

	<action name="obtain-lock_for_initializing">
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.lock.LockManagingProcess</arg>
			<arg>-Pzk_session_timeout=${zk_session_timeout}</arg>
			<arg>-Pnode_id=${cache_location}</arg>
			<arg>-Pmode=obtain</arg>
		</java>
		<ok to="get-new-cache-id_for_initializing" />
		<error to="release-lock-and-fail" />
	</action>

	<action name='get-new-cache-id_for_initializing'>
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.cache.CacheMetadataManagingProcess</arg>
			<arg>-Pdefault_cache_location=${cache_location}</arg>
			<arg>-Pmode=generate_new_id</arg>
			<capture-output />
		</java>
		<ok to="prepare_cache_for_initializing" />
		<error to="release-lock-and-fail" />
	</action>

	<action name="prepare_cache_for_initializing">
		<fs>
			<mkdir path="${nameNode}${cache_location}/${wf:actionData('get-new-cache-id_for_initializing')['cache_id']}" />
		</fs>
		<ok to="initialize_meta_cache" />
		<error to="release-lock-and-fail" />
	</action>

	<action name="initialize_meta_cache">
		<distcp xmlns="uri:oozie:distcp-action:0.1">
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<arg>${nameNode}${workingDir}/metadata_extractor/output_root/meta</arg>
			<arg>${nameNode}${cache_location}/${wf:actionData('get-new-cache-id_for_initializing')['cache_id']}/meta</arg>
		</distcp>
		<ok to="write-new-cache-id_for_initializing" />
		<error to="fail-initialize_cache-temp_files_cleanup" />
	</action>

	<action name="fail-initialize_cache-temp_files_cleanup">
		<fs>
			<delete path="${nameNode}${cache_location}/${wf:actionData('get-new-cache-id_for_initializing')['cache_id']}" />
		</fs>
		<ok to="release-lock-and-fail" />
		<error to="release-lock-and-fail" />
	</action>

	<action name='write-new-cache-id_for_initializing'>
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.cache.CacheMetadataManagingProcess</arg>
			<arg>-Pdefault_cache_location=${cache_location}</arg>
			<arg>-Pmode=write_id</arg>
			<arg>-Pid=${wf:actionData('get-new-cache-id_for_initializing')['cache_id']}</arg>
			<capture-output />
		</java>
		<ok to="release-lock-and-end" />
		<error to="fail-initialize_cache-temp_files_cleanup" />
	</action>

	<!-- end of full input processing block, no cache was provided as an input -->

	<!-- lock releasing actions -->
	<action name="release-lock-and-fail">
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.lock.LockManagingProcess</arg>
			<arg>-Pzk_session_timeout=${zk_session_timeout}</arg>
			<arg>-Pnode_id=${cache_location}</arg>
			<arg>-Pmode=release</arg>
		</java>
		<ok to="fail" />
		<error to="fail" />
	</action>

	<action name="release-lock-and-end">
		<java>
			<main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.common.lock.LockManagingProcess</arg>
			<arg>-Pzk_session_timeout=${zk_session_timeout}</arg>
			<arg>-Pnode_id=${cache_location}</arg>
			<arg>-Pmode=release</arg>
		</java>
		<ok to="finalize" />
		<error to="fail" />
	</action>

	<decision name="finalize">
		<switch>
			<case to="remove_sideproducts">${remove_sideproducts eq "true"}</case>
			<default to="end" />
		</switch>
	</decision>

	<action name="remove_sideproducts">
		<fs>
			<delete path="${nameNode}${workingDir}" />
		</fs>
		<ok to="end" />
		<error to="fail" />
	</action>

	<kill name="fail">
		<message>Unfortunately, the process failed -- error message:
			[${wf:errorMessage(wf:lastErrorNode())}]
		</message>
	</kill>
	<end name="end" />
</workflow-app>