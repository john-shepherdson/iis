<workflow-app xmlns="uri:oozie:workflow:0.4" name="transformers_metadataextraction_skip_extracted">
	
	<parameters>
		<property>
			<name>input_document_content</name>
			<description>document content input</description>
		</property>
		<property>
			<name>input_document_meta</name>
			<description>document extracted metadata input</description>
		</property>
		<property>
			<name>output_document_content</name>
			<description>document content output: all contents which were not processed so far, based in input_document_meta inspection</description>
		</property>
		<property>
			<name>output_document_meta</name>
			<description>document extracted metadata ouput: all metadata records which were already processed, found in input_document_meta</description>
		</property>
		<property>
			<name>mapred_map_child_java_opts</name>
			<value>-Xmx4g</value>
			<description>mapper java-opts, e.g. maximum heap size for a single JVM running MapReduce</description>
		</property>
		<property>
			<name>mapred_reduce_child_java_opts</name>
			<value>-Xmx4g</value>
			<description>reducer java-opts, e.g. maximum heap size for a single JVM running MapReduce</description>
		</property>
	</parameters>
    
    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
        </configuration>
    </global>
    
    
    <start to="generate-schema"/>
    
    <action name="generate-schema">
	    <java>
	        <main-class>eu.dnetlib.iis.common.javamapreduce.hack.AvroSchemaGenerator</main-class>
	        <arg>eu.dnetlib.iis.importer.auxiliary.schemas.DocumentContentUrl</arg>
	        <arg>eu.dnetlib.iis.metadataextraction.schemas.ExtractedDocumentMetadata</arg>
	        <capture-output />
	    </java>
	    <ok to="transformer" />
	    <error to="fail" />
	</action>
	
    <action name="transformer">
        <pig>
			<!-- The data generated by this node is deleted in this section -->
			<prepare>
				<delete path="${nameNode}${output_document_content}" />
				<delete path="${nameNode}${output_document_meta}" />
			</prepare>
            <configuration>
                <property>
                    <name>mapreduce.map.java.opts</name>
                    <value>${mapred_map_child_java_opts}</value>
                </property>
                <property>
                    <name>mapreduce.reduce.java.opts</name>
                    <value>${mapred_reduce_child_java_opts}</value>
                </property>
            </configuration>
            <!-- Path to PIG script the workflow executes. -->
            <script>lib/scripts/transformer.pig</script>
            
            <param>schema_document_content=${wf:actionData('generate-schema')['eu.dnetlib.iis.importer.auxiliary.schemas.DocumentContentUrl']}</param>
            <param>schema_document_meta=${wf:actionData('generate-schema')['eu.dnetlib.iis.metadataextraction.schemas.ExtractedDocumentMetadata']}</param>
            
            <param>input_document_content=${input_document_content}</param>
            <param>input_document_meta=${input_document_meta}</param>
            
            <param>output_document_content=${output_document_content}</param>
            <param>output_document_meta=${output_document_meta}</param>
            
        </pig>
        <ok to="end"/>
        <error to="fail"/>
    </action>
    <kill name="fail">
		<message>Unfortunately, the workflow failed -- error message:
			[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>
    <end name="end"/>
</workflow-app>
